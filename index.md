# Shreyanth H G

AI/ML Engineer | Researcher | LLM Optimization

Location: Bengaluru, Karnataka, India

Email: [shreyanthhg1427@gmail.com](mailto:shreyanthhg.dev@gmail.com)

LinkedIn: [https://linkedin.com/in/shreyanth-h-g-26b35a22b](https://linkedin.com/in/shreyanth-h-g-26b35a22b)

---

## Objective

I am a dedicated and forward-thinking Artificial Intelligence and Machine Learning Engineer with robust experience in building and optimizing scalable AI systems. My expertise encompasses a broad range of machine learning models, deep learning architectures, generative AI frameworks, and edge deployment strategies for real-time inference and IoT integration. Currently employed at Accurate Info Solution in Bengaluru, I focus on developing innovative ML pipelines and deploying models in low-resource environments, particularly optimizing large language models (LLMs) for constrained hardware setups. My objective is to contribute to meaningful research and enterprise-ready AI products that push the boundaries of what's possible in intelligent computing systems.

---

## Education

* **Master of Science in Artificial Intelligence and Machine Learning**, Liverpool John Moores University (Virtual Mode via UpGrad), 2023 – 2025
* **Postgraduate Program in Computational Data Science**, Case Western Reserve University (via UpGrad), 2021 – 2023
* **Bachelor of Engineering in Computer Science**, East West Institute of Technology, Bangalore, 2018 – 2022

---

## Certifications

* Post Graduation Program in Computational Data Science
* PGP in Artificial Intelligence (Collaborated with LJMU Masters Program)
* Google Cloud Skill Boost Badges
* IBM Skill Badges

---

## Skills

### Machine Learning and Deep Learning Frameworks

Proficient in multiple frameworks and libraries crucial to building scalable, interpretable, and efficient models. My experience includes:

* **PyTorch** and **TensorFlow** for building CNNs, RNNs, LSTMs, GANs, and transformers from scratch and with pre-trained models.
* **Scikit-learn** for traditional machine learning tasks including classification, regression, clustering, and dimensionality reduction.
* **Keras** for rapid prototyping and model experimentation.
* **Hugging Face Transformers** for LLM fine-tuning, transfer learning, and prompt-based tasks.
* **ONNX** for model conversion and cross-platform deployment.
* **Timm** (PyTorch Image Models) for using state-of-the-art image architectures and transfer learning models like EfficientNet and ConvNeXt.

### Data Engineering and Processing

Effective data engineering is foundational to model performance. I handle various data types:

* **Pandas and NumPy** for data cleaning, manipulation, and preparation.
* Complex pipelines for **image/video/CSV/text handling**.
* Techniques such as **missing value imputation**, **outlier detection**, and **feature encoding**.
* Design of modular **feature engineering pipelines** for reproducible ML workflows.

### Data Analytics and Visualization

Using analytics to gain actionable insights from raw data:

* **Exploratory Data Analysis (EDA)** using matplotlib, seaborn, and pandas profiling.
* Building **predictive** and **descriptive models** for classification and regression problems.
* **Statistical feature selection techniques** including mutual information and recursive feature elimination.
* **Correlation analysis**, heatmaps, distribution plots, and anomaly detection.

### Advanced Modeling Techniques

My research and practical expertise spans several areas:

* **LoRA** and **QLoRA** for low-rank adaptation and quantized efficient fine-tuning of LLMs.
* **SCALE**: My proprietary method for selective adapter injection in transformer models based on activation profiling and layer scoring.
* Architectures such as **CNNs**, **GANs**, **ViT**, **BERT**, **T5**, and **GRU/LSTM** for various domains including computer vision, NLP, and time-series.

### Large Language Models (LLMs)

Proficient in fine-tuning and optimizing LLMs such as:

* **GPT-2**, **T5**, **BERT** for domain-specific generation and comprehension tasks.
* Implementation of **attention manipulation**, **prompt engineering**, and **adapter-based tuning**.
* Evaluation using BLEU, ROUGE, perplexity, and log-likelihood.

### Optimization and Efficiency Techniques

Skilled in improving performance and memory usage in constrained environments:

* **Mixed Precision Training (fp16)** to reduce memory footprint.
* **Gradient Accumulation** and **Layer-wise Profiling** to manage resource utilization.
* Custom **training profilers** for monitoring GPU/CPU/RAM usage.

### Computer Vision (CV)

Developed models and systems for image and video-based analysis:

* Object detection using **YOLOv12**, instance segmentation.
* **OpenCV** for pre-processing and image analysis.
* Visual explainability via **Grad-CAM**, CAM++, and integrated heatmaps.
* Custom detection models deployed to embedded devices.

### Natural Language Processing (NLP)

Worked on the full pipeline from raw text to model-driven insights:

* **Sentiment analysis**, **topic modeling**, and **transformer-based text classification**.
* **QA systems**, **Named Entity Recognition**, and **text summarization**.
* Fine-tuning transformers on domain-specific corpora.

### Edge AI and AIoT Integration

Designed full-stack embedded pipelines:

* Real-time inference using **ESP32**, **ESP8266**, and **Arduino Uno**.
* GPIO-triggered models, sensor fusion, and feedback loops.
* Hardware communication using **serial**, **I2C**, and **PyFirmata**.

### Deployment and Inference Tools

* Deployment-ready models using **TorchScript**, **ONNX Export**.
* Built **Streamlit** dashboards and model UIs.
* SQLite-based logging systems for inference result tracking.

### Experimentation and Logging Tools

* Visual experiment tracking using **WandB** and **TensorBoard**.
* Developed **custom dashboards** for client-facing model reports.
* Runtime logging of training loss, validation metrics, and inference latency.

### Tools & Platforms

* Version control with **Git and GitHub**.
* IDEs: Jupyter, VSCode, Colab.
* Backend APIs using **Django**.


## Certifications

* Post Graduation Program in Computational Data Science
* PGP in Artificial Intelligence (Collaborated with LJMU Masters Program)
* Google Cloud Skill Boost Badges
* IBM Skill Badges


## Experience

### AI/ML Engineer — Accurate Info Solution (Aug 2023 – Present)

At Accurate Info Solution, I was entrusted with leading multiple research-backed AI projects under startup constraints. My primary responsibility was to deliver cutting-edge ML prototypes that could be quickly transformed into production-ready solutions. By leveraging my experience in adapter-based fine-tuning techniques such as LoRA and SCALE, I reduced the GPU memory footprint of LLM training by 35% and cut down fine-tuning time by 40% across multiple deployments of GPT-2 and BERT models.

I also built reusable ML pipelines that interfaced directly with edge-based camera systems such as the ESP32-CAM, enabling real-time inference for anomaly detection and facial stress classification. These pipelines were deployed with Streamlit and TorchScript for smooth client delivery. Alongside this, I mentored a cohort of 5+ interns on key concepts of AI deployment, helping develop three working PoC systems covering AIOT use-cases and generative model integrations.

### Jr. Data Scientist (Trainee) — TuringMinds.AI (Feb 2022 – May 2023)

During my tenure at TuringMinds.AI, I worked on a variety of data science projects that honed my model-building and data wrangling skills. One of the significant accomplishments was developing a neural network architecture entirely from scratch using Python and NumPy, bypassing all high-level libraries. This network achieved an accuracy of 88% on synthetic datasets and was later integrated into a modular pipeline.

Another core task involved the enhancement of a No-Code AI platform. I contributed toward increasing its modular flexibility by designing reusable plug-in components, making AI more accessible for non-developers. Moreover, I designed analytical dashboards using Plotly and Seaborn for data insights on datasets provided by NASA and Mercedes-Benz, as well as conducted complex preprocessing for handling outliers, missing values, and class imbalance issues.

---

## Projects

### SCALE: Adaptive Adapter Fine-Tuning Engine

SCALE (Selective Composition for Adapter Layer Efficiency) is a novel adapter-injection engine I developed to inject trainable adapters into high-importance transformer layers based on profiling scores. The system dynamically analyzes activation weights and computes a rank score that guides where to place the adapters. It supports encoder-only (BERT), decoder-only (GPT-2), and encoder-decoder (T5) models. With this innovation, training time was reduced by 40%, and memory usage was optimized, making it viable for fine-tuning on limited-resource systems.

### Smart Document Retrieval using Retrieval-Augmented Generation (RAG)

This project focused on the fusion of traditional search indexing and transformer-based QA. I built a smart assistant using RAG architecture that integrates Dense Passage Retrieval (DPR) with BART to perform sub-second document search and query response. It was deployed for corporate document automation and yielded high performance in benchmark QA tests with multi-document support.

### Content-Based Image Retrieval (CBIR) with Feature Fusion

In this hybrid CBIR project, I combined features from deep models (InceptionV3) with handcrafted descriptors (like LBP, Gabor filters) to achieve robust image similarity matching, particularly for super-resolution textures. This dual-stream fusion approach outperformed standalone deep or handcrafted models on VISTEX and STEX datasets, achieving improved precision and F1-measure.

### Edge AIOT Sensor-Triggered Pipeline

This embedded system project integrated ESP32-CAM modules with GPIO-controlled servo motors to create a real-time pipeline for detecting object classes and responding with physical movement. This application was critical for surveillance, automated gates, and object redirection systems. Inference latency was optimized to 1.2 seconds, and deployment was realized using ONNX and lightweight CV models.

---

## Leadership & Outreach

Throughout my career, I have actively contributed to the AI/ML community through mentorship and educational initiatives. At BGSCET, I organized and led a hands-on GenAI workshop for over 290 students. The session covered fundamentals of transformer architectures, prompt tuning strategies, and generative AI applications in real-world scenarios.

I was also invited as the keynote speaker for a Data Science Workshop at RRCE, where I presented a technical session on statistical modeling, applied EDA, and data storytelling using case studies. In my current organization, I mentor interns and junior engineers, assisting in structuring their ML projects, reviewing their pipelines, and guiding them through the research and implementation phases. My mentorship has resulted in successful delivery of projects in low-resource LLM tuning and edge computer vision deployment.

---
